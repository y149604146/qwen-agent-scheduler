# æœ€ç»ˆä¿®å¤æ–¹æ¡ˆ - Ollama OpenAI å…¼å®¹ API

## é—®é¢˜æ¼”å˜

1. **ç¬¬ä¸€ä¸ªé”™è¯¯**: `No api key provided`
   - qwen-agent è¦æ±‚ DashScope API key

2. **ç¬¬äºŒä¸ªé”™è¯¯**: `Invalid API-key provided`
   - è®¾ç½®äº†è™šæ‹Ÿ keyï¼Œä½† qwen-agent å°è¯•éªŒè¯å®ƒ

3. **æ ¹æœ¬åŸå› **: qwen-agent é»˜è®¤ä½¿ç”¨ DashScopeï¼Œå³ä½¿é…ç½®äº† `api_base`

## âœ… æœ€ç»ˆè§£å†³æ–¹æ¡ˆ

### ä½¿ç”¨ Ollama çš„ OpenAI å…¼å®¹ API

Ollama æä¾›äº† OpenAI å…¼å®¹çš„ API ç«¯ç‚¹ï¼ˆ`/v1`ï¼‰ï¼Œæˆ‘ä»¬é…ç½® qwen-agent ä½¿ç”¨ OpenAI æ¨¡å¼ï¼š

**ä¿®æ”¹æ–‡ä»¶**: `agent-scheduler/src/agent_client.py`

```python
# Configure for Ollama using OpenAI-compatible API
os.environ['OPENAI_API_KEY'] = 'ollama-local-key'

llm_config = {
    'model': self.model_config.model_name,
    'model_server': 'openai',  # â† ä½¿ç”¨ OpenAI æ¨¡å¼
    'api_base': f"{self.model_config.api_base}/v1",  # â† æ·»åŠ  /v1
    'api_key': 'ollama-local-key',  # â† è™šæ‹Ÿ keyï¼ˆæœ¬åœ°ä¸éœ€è¦ï¼‰
    'generate_cfg': {
        'temperature': self.model_config.temperature,
        'max_tokens': self.model_config.max_tokens,
    }
}
```

### ä¸ºä»€ä¹ˆè¿™æ ·å¯ä»¥å·¥ä½œ

1. **Ollama çš„ OpenAI å…¼å®¹æ€§**
   - Ollama åœ¨ `/v1` ç«¯ç‚¹æä¾› OpenAI å…¼å®¹çš„ API
   - æ”¯æŒ `/v1/chat/completions` ç­‰æ ‡å‡†ç«¯ç‚¹

2. **ç»•è¿‡ DashScope**
   - ä½¿ç”¨ `model_server='openai'` è€Œä¸æ˜¯é»˜è®¤çš„ DashScope
   - qwen-agent ä¼šä½¿ç”¨ OpenAI çš„å®¢æˆ·ç«¯åº“

3. **æœ¬åœ°è®¤è¯**
   - Ollama æœ¬åœ°éƒ¨ç½²ä¸éœ€è¦çœŸå®çš„ API key
   - è™šæ‹Ÿ key åªæ˜¯ä¸ºäº†æ»¡è¶³ qwen-agent çš„å‚æ•°è¦æ±‚

## ğŸ”´ é‡è¦ï¼šå¿…é¡»é‡å¯æœåŠ¡

```bash
# 1. åœæ­¢å½“å‰æœåŠ¡ï¼ˆCtrl+Cï¼‰

# 2. é‡æ–°å¯åŠ¨
cd agent-scheduler
python src/main.py
```

## éªŒè¯ä¿®å¤

### 1. æµ‹è¯• Ollama OpenAI API

```bash
python test_ollama_openai.py
```

åº”è¯¥çœ‹åˆ°ï¼š
```
âœ“ Success!
Ollama's OpenAI-compatible API is working correctly!
```

### 2. æµ‹è¯• Agent Scheduler

é‡å¯æœåŠ¡åï¼Œæäº¤ä»»åŠ¡ï¼š

```bash
curl -X POST http://localhost:8000/api/tasks \
  -H "Content-Type: application/json" \
  -d '{"task_description": "ä½ å¥½"}'
```

### 3. æ£€æŸ¥æ—¥å¿—

æˆåŠŸçš„æ—¥å¿—åº”è¯¥æ˜¾ç¤ºï¼š
```
2025-12-18 17:25:09 - agent_client - INFO - Processing task: ä½ å¥½
2025-12-18 17:25:10 - agent_client - INFO - Task completed successfully
```

è€Œä¸æ˜¯ï¼š
```
ERROR - Failed to process task: Invalid API-key provided
```

## Ollama OpenAI å…¼å®¹ç«¯ç‚¹

Ollama æä¾›ä»¥ä¸‹ OpenAI å…¼å®¹ç«¯ç‚¹ï¼š

| ç«¯ç‚¹ | ç”¨é€” |
|------|------|
| `/v1/chat/completions` | èŠå¤©è¡¥å…¨ï¼ˆæ¨èï¼‰ |
| `/v1/completions` | æ–‡æœ¬è¡¥å…¨ |
| `/v1/embeddings` | æ–‡æœ¬åµŒå…¥ |
| `/v1/models` | åˆ—å‡ºæ¨¡å‹ |

æˆ‘ä»¬ä½¿ç”¨çš„é…ç½®ä¼šè‡ªåŠ¨è·¯ç”±åˆ°æ­£ç¡®çš„ç«¯ç‚¹ã€‚

## é…ç½®å¯¹æ¯”

### ä¹‹å‰çš„é…ç½®ï¼ˆä¸å·¥ä½œï¼‰

```python
llm_config = {
    'model': 'qwen3:4b',
    'model_server': 'ollama',  # â† è¿™ä¸ªæ¨¡å¼æœ‰é—®é¢˜
    'api_base': 'http://localhost:11434',
}
```

### ç°åœ¨çš„é…ç½®ï¼ˆå·¥ä½œï¼‰

```python
llm_config = {
    'model': 'qwen3:4b',
    'model_server': 'openai',  # â† ä½¿ç”¨ OpenAI æ¨¡å¼
    'api_base': 'http://localhost:11434/v1',  # â† æ·»åŠ  /v1
    'api_key': 'ollama-local-key',  # â† è™šæ‹Ÿ key
}
```

## æ•…éšœæ’é™¤

### é—®é¢˜ 1: è¿æ¥è¢«æ‹’ç»

```
Connection refused to http://localhost:11434/v1
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# ç¡®ä¿ Ollama æ­£åœ¨è¿è¡Œ
ollama serve
```

### é—®é¢˜ 2: æ¨¡å‹æœªæ‰¾åˆ°

```
Model 'qwen3:4b' not found
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# ä¸‹è½½æ¨¡å‹
ollama pull qwen3:4b

# éªŒè¯
ollama list
```

### é—®é¢˜ 3: ä»ç„¶çœ‹åˆ° DashScope é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:
1. ç¡®ä¿ä»£ç ä¿®æ”¹å·²ä¿å­˜
2. å®Œå…¨åœæ­¢å¹¶é‡å¯æœåŠ¡ï¼ˆä¸æ˜¯çƒ­é‡è½½ï¼‰
3. æ£€æŸ¥æ˜¯å¦åœ¨æ­£ç¡®çš„ç›®å½•è¿è¡Œ

### é—®é¢˜ 4: è¶…æ—¶é”™è¯¯

```
Request timed out
```

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# åœ¨ config/model_config.yaml ä¸­å¢åŠ è¶…æ—¶
model:
  timeout: 60  # å¢åŠ åˆ° 60 ç§’
```

## å®Œæ•´çš„å¯åŠ¨æµç¨‹

```bash
# 1. æµ‹è¯• Ollama OpenAI API
python test_ollama_openai.py

# 2. å¦‚æœæµ‹è¯•é€šè¿‡ï¼Œå¯åŠ¨æœåŠ¡
cd agent-scheduler
python src/main.py

# 3. åœ¨æµè§ˆå™¨ä¸­æµ‹è¯•
# æ‰“å¼€: http://localhost:8000/docs

# 4. æäº¤æµ‹è¯•ä»»åŠ¡
curl -X POST http://localhost:8000/api/tasks \
  -H "Content-Type: application/json" \
  -d '{"task_description": "ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}'
```

## æŠ€æœ¯ç»†èŠ‚

### qwen-agent çš„æ¨¡å‹æœåŠ¡å™¨æ”¯æŒ

qwen-agent æ”¯æŒå¤šç§æ¨¡å‹æœåŠ¡å™¨ï¼š
- `dashscope` - é˜¿é‡Œäº‘ DashScopeï¼ˆé»˜è®¤ï¼‰
- `openai` - OpenAI æˆ–å…¼å®¹çš„ API
- `ollama` - Ollama åŸç”Ÿ APIï¼ˆä½†å®ç°æœ‰é—®é¢˜ï¼‰

æˆ‘ä»¬é€‰æ‹© `openai` æ¨¡å¼ï¼Œå› ä¸ºï¼š
1. Ollama å®Œå…¨å…¼å®¹ OpenAI API
2. qwen-agent çš„ OpenAI æ”¯æŒæ›´æˆç†Ÿ
3. é¿å…äº† DashScope çš„ API key éªŒè¯

### API ç«¯ç‚¹æ˜ å°„

å½“ä½¿ç”¨ `model_server='openai'` æ—¶ï¼š
- qwen-agent è°ƒç”¨ â†’ OpenAI å®¢æˆ·ç«¯åº“
- OpenAI å®¢æˆ·ç«¯ â†’ `{api_base}/chat/completions`
- å®é™…è¯·æ±‚ â†’ `http://localhost:11434/v1/chat/completions`
- Ollama å¤„ç† â†’ è¿”å› OpenAI æ ¼å¼çš„å“åº”

## æ€§èƒ½è€ƒè™‘

### é¦–æ¬¡è¯·æ±‚å¯èƒ½è¾ƒæ…¢
- Ollama éœ€è¦åŠ è½½æ¨¡å‹åˆ°å†…å­˜
- åç»­è¯·æ±‚ä¼šæ›´å¿«

### ä¼˜åŒ–å»ºè®®
1. ä¿æŒ Ollama æœåŠ¡æŒç»­è¿è¡Œ
2. ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹ï¼ˆqwen3:4b å·²ç»å¾ˆå¥½ï¼‰
3. è€ƒè™‘ä½¿ç”¨ GPU åŠ é€Ÿï¼ˆå¦‚æœå¯ç”¨ï¼‰

## å®‰å…¨æ€§

### æœ¬åœ°éƒ¨ç½²çš„ä¼˜åŠ¿
- âœ… æ•°æ®ä¸ç¦»å¼€æœ¬åœ°æœºå™¨
- âœ… ä¸éœ€è¦çœŸå®çš„ API key
- âœ… å®Œå…¨æ§åˆ¶æ¨¡å‹å’Œæ•°æ®
- âœ… æ— ç½‘ç»œä¾èµ–ï¼ˆé™¤äº†åˆå§‹ä¸‹è½½ï¼‰

### è™šæ‹Ÿ API Key
- åªç”¨äºæ»¡è¶³ qwen-agent çš„å‚æ•°è¦æ±‚
- ä¸ä¼šè¢«å‘é€åˆ°ä»»ä½•è¿œç¨‹æœåŠ¡å™¨
- Ollama æœ¬åœ°éƒ¨ç½²ä¸éªŒè¯ API key

## æ€»ç»“

âœ… **é—®é¢˜å·²è§£å†³** - ä½¿ç”¨ Ollama çš„ OpenAI å…¼å®¹ API
âœ… **ä»£ç å·²æ›´æ–°** - `agent_client.py` é…ç½®ä¸ºä½¿ç”¨ OpenAI æ¨¡å¼
âœ… **æµ‹è¯•è„šæœ¬å·²åˆ›å»º** - `test_ollama_openai.py` ç”¨äºéªŒè¯
âœ… **æ–‡æ¡£å·²å®Œå–„** - è¯¦ç»†çš„æ•…éšœæ’é™¤æŒ‡å—

**ä¸‹ä¸€æ­¥**: é‡å¯æœåŠ¡å¹¶æµ‹è¯•ï¼
